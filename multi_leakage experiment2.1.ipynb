{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN 4 outputs and with and without sorting of outputs\n",
    "model_path = 'saved_model/Multi_leak/experiment2/withoutswap/'\n",
    "project_name='Multi_leak_experiment2_withoutSwap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n",
      "# GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2 - 1 output layer with 1 loss function - mse. and do hyper parameter tuning.\n",
    "from utils.data_preprocess import load_data, load_single_leakage_model_data\n",
    "from utils.module import model_eval, hyper_model, model_comparison, linear_regression, numpy_to_tensor, benchmark_linear_model\n",
    "import itertools\n",
    "import pandas as pd \n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x1', 'y1', 'MFC6', 'MFC7', 'MFC8', 'MFC9', 'MFC10', 'MFC1', 'MFC2',\n",
      "       'MFC3', 'MFC4', 'MFC5', 'x2', 'y2'],\n",
      "      dtype='object')\n",
      "x1       0\n",
      "y1       0\n",
      "MFC6     0\n",
      "MFC7     0\n",
      "MFC8     0\n",
      "MFC9     0\n",
      "MFC10    0\n",
      "MFC1     0\n",
      "MFC2     0\n",
      "MFC3     0\n",
      "MFC4     0\n",
      "MFC5     0\n",
      "x2       0\n",
      "y2       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "single_leakage, two_leakage = load_data()\n",
    "# two_leakage[\"leak_1\"] = 1\n",
    "# two_leakage[\"leak_2\"] = 1\n",
    "\n",
    "# single_leakage[\"leak_1\"] = 1\n",
    "# single_leakage[\"leak_2\"] = 0\n",
    "\n",
    "data = pd.concat([single_leakage, two_leakage], axis=0)\n",
    "data['x2'] = data['x2'].replace(np.nan, 8024)\n",
    "data['y2'] = data['y2'].replace(np.nan, 2616.5)\n",
    "\n",
    "data = data.drop(columns=['mfc6_residual',\n",
    "       'mfc7_residual', 'mfc8_residual', 'mfc9_residual', 'mfc10_residual',\n",
    "       'mfc1_residual', 'mfc2_residual', 'mfc3_residual', 'mfc4_residual',\n",
    "       'mfc5_residual', 'total flow rate'])\n",
    "\n",
    "print(data.columns)\n",
    "print(data.isna().sum())\n",
    "\n",
    "y = data[['x1', 'y1', 'x2', 'y2']]\n",
    "x = data.drop(['x1', 'y1', 'x2', 'y2'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1) \n",
    "\n",
    "y1_train = y_train[['x1', 'y1', 'x2', 'y2']]\n",
    "# y2_train = y_train[['leak_1', 'leak_2']]\n",
    "y1_test = y_test[['x1', 'y1', 'x2', 'y2']]\n",
    "# y2_test = y_test[['leak_1', 'leak_2']]\n",
    "y1_val = y_val[['x1', 'y1', 'x2', 'y2']]\n",
    "# y2_val = y_val[['leak_1', 'leak_2']]\n",
    "\n",
    "def coords_swap(y1):\n",
    "    s = y1['x2'] < y1['x1']\n",
    "    y1.loc[s, ['x1','x2']] = y1.loc[s, ['x2','x1']].values\n",
    "    y1.loc[s, ['y1','y2']] = y1.loc[s, ['y2','y1']].values\n",
    "    return y1\n",
    "\n",
    "# y1_data = [y1_train, y1_val, y1_test]\n",
    "# y1_data_types = ['y1_train', 'y1_val', 'y1_test']\n",
    "# for y1_data_types, y1 in zip(y1_data_types, y1_data):\n",
    "#     y1_data_types = coords_swap(y1)\n",
    "\n",
    "y1_columns = y1_train.columns\n",
    "# y2_columns = y2_train.columns\n",
    "X_columns = X_train.columns\n",
    "\n",
    "scaler_coords1 = StandardScaler()\n",
    "y1_train = scaler_coords1.fit_transform(y1_train)\n",
    "y1_test = scaler_coords1.transform(y1_test)\n",
    "y1_val = scaler_coords1.transform(y1_val)\n",
    "\n",
    "y_train_sc = pd.DataFrame(y1_train, columns=y1_columns)\n",
    "y_test_sc = pd.DataFrame(y1_test, columns=y1_columns)\n",
    "y_val_sc = pd.DataFrame(y1_val, columns=y1_columns)\n",
    "\n",
    "# y1_train['x2'] = y1_train['x2'].replace(np.nan, -5)\n",
    "# y1_train['y2'] = y1_train['y2'].replace(np.nan, -5)\n",
    "\n",
    "# y1_test['x2'] = y1_test['x2'].replace(np.nan, -5)\n",
    "# y1_test['y2'] = y1_test['y2'].replace(np.nan, -5)\n",
    "\n",
    "# y1_val['x2'] = y1_val['x2'].replace(np.nan, -5)\n",
    "# y1_val['y2'] = y1_val['y2'].replace(np.nan, -5)\n",
    "# Not sure if 0 is good enough or try generating a random number\n",
    "\n",
    "# scaler_coords2 = StandardScaler()\n",
    "# y2_train = scaler_coords2.fit_transform(y2_train)\n",
    "# y2_test = scaler_coords2.fit_transform(y2_test)\n",
    "# y2_val = scaler_coords2.transform(y2_val)\n",
    "\n",
    "# y2_train = pd.DataFrame(y2_train, columns=y2_columns)\n",
    "# y2_test = pd.DataFrame(y2_test, columns=y2_columns)\n",
    "# y2_val = pd.DataFrame(y2_val, columns=y2_columns)\n",
    "\n",
    "# y2_train = y2_train.reset_index().drop(columns='sample_number')\n",
    "# y2_val = y2_val.reset_index().drop(columns='sample_number')\n",
    "# y2_test = y2_test.reset_index().drop(columns='sample_number')\n",
    "\n",
    "# y_train_sc = pd.concat([y1_train, y2_train], axis=1)\n",
    "# y_test_sc = pd.concat([y1_test, y2_test], axis=1)\n",
    "# y_val_sc = pd.concat([y1_val, y2_val], axis=1)\n",
    "\n",
    "scaler_flows = StandardScaler()\n",
    "X_train = scaler_flows.fit_transform(X_train)\n",
    "X_test = scaler_flows.transform(X_test)\n",
    "X_val = scaler_flows.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model using model builder from keras tuner\n",
    "def model_builder_single(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Choose an optimal value between 32-512\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 15)):\n",
    "        l1_weight = hp.Choice('l1_weight', values=[0.0, 1e-1, 1e-2, 1e-3])\n",
    "        l2_weight = hp.Choice('l2_weight', values=[0.0, 1e-1, 1e-2, 1e-3])\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1 = l1_weight, l2 = l2_weight)\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"elu\"]),\n",
    "                kernel_initializer='he_uniform',\n",
    "                kernel_regularizer=kernel_regularizer\n",
    "            )\n",
    "        )\n",
    "        if hp.Boolean(\"dropout\"):\n",
    "            model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(keras.layers.Dense(units=4, activation= \"linear\", kernel_initializer='he_uniform'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    # hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-1, sampling=\"log\")\n",
    "\n",
    "    # model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    #             loss=\"mse\",  metrics='mae')\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=learning_rate),\n",
    "                loss=\"mse\",\n",
    "                metrics='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#search for the best hyperparameters and train the standard model with original training data\n",
    "def hyper_model(X_train,Y_train, X_val, y_val, epoch, factor):\n",
    "    folder_name = project_name\n",
    "    tuner = kt.Hyperband(model_builder_single,\n",
    "                         objective='val_loss',\n",
    "                         max_epochs=epoch+100,\n",
    "                         factor=factor,\n",
    "                         hyperband_iterations = 1,\n",
    "                        # Integer, at least 1, the number of times to iterate over the full Hyperband algorithm. One iteration will \n",
    "                        # run approximately max_epochs * (math.log(max_epochs, factor) ** 2) cumulative epochs across all trials. It is \n",
    "                        # recommended to set this to as high a value as is within your resource budget. Defaults to 1.\n",
    "                         directory=\"../../tensorflow_log_files/studienarbeit/\",\n",
    "                         seed=0,    \n",
    "                         project_name=str(folder_name))\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    tuner.search(X_train, Y_train, epochs=epoch, validation_data = (X_val, y_val), callbacks=[stop_early, \n",
    "                                                                                            #   keras.callbacks.TensorBoard(\"../tensorflow_log_files/studienarbeit/tb_logs\"+str(folder_name))\n",
    "                                                                                              ])\n",
    "    #tuner.search(X_train, Y_train, epochs=50, validation_data=(X_test,Y_test), callbacks=[stop_early])\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    history = model.fit(X_train, Y_train, epochs=epoch, validation_data = (X_val, y_val), shuffle= True)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
    "    is {model.optimizer.lr.numpy()}.\n",
    "    \"\"\")\n",
    "\n",
    "    return best_hps, model, tuner, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 03s]\n",
      "val_loss: 4.7720034451834294\n",
      "\n",
      "Best val_loss So Far: 4.7720034451834294\n",
      "Total elapsed time: 00h 00m 03s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "11                |1                 |num_layers\n",
      "0.001             |0.01              |l1_weight\n",
      "0.001             |0.1               |l2_weight\n",
      "448               |96                |units_0\n",
      "elu               |elu               |activation\n",
      "False             |True              |dropout\n",
      "0.0044198         |0.01417           |lr\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "10                |10                |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage experiment2.1.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_hps, best_model, tuner, history \u001b[39m=\u001b[39m hyper_model(X_train,y_train_sc, X_val, y_val_sc,\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                         epoch\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,factor\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage experiment2.1.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m tuner\u001b[39m.\u001b[39msearch_space_summary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m stop_early \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train, Y_train, epochs\u001b[39m=\u001b[39;49mepoch, validation_data \u001b[39m=\u001b[39;49m (X_val, y_val), callbacks\u001b[39m=\u001b[39;49m[stop_early, \n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m                                                                                         \u001b[39m#   keras.callbacks.TensorBoard(\"../tensorflow_log_files/studienarbeit/tb_logs\"+str(folder_name))\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m                                                                                           ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m#tuner.search(X_train, Y_train, epochs=50, validation_data=(X_test,Y_test), callbacks=[stop_early])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/Work/studienarbeit/leakage_detection_cfrp/multi_leakage%20experiment2.1.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m best_hps \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/tuners/hyperband.py:425\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    424\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 425\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:959\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    960\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    962\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    963\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    964\u001b[0m           args, kwds))\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/studiarbeit/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_hps, best_model, tuner, history = hyper_model(X_train,y_train_sc, X_val, y_val_sc,\n",
    "                                                        epoch=1000,factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(10, 224), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555da0eb50>, 140007640827584), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(224,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d96b550>, 140004620411824), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(224, 288), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d92b400>, 140004620224192), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(288,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d955430>, 140004620225072), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(288, 160), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8fe430>, 140004620223712), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(160,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8a6460>, 140004620249168), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(160, 416), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8d1460>, 140004620251504), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(416,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d87b490>, 140004620252384), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(416, 4), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d826490>, 140004620254624), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(4,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d853520>, 140004620280016), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(10, 224), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555da0eb50>, 140007640827584), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(224,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d96b550>, 140004620411824), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(224, 288), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d92b400>, 140004620224192), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(288,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d955430>, 140004620225072), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(288, 160), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8fe430>, 140004620223712), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(160,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8a6460>, 140004620249168), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(160, 416), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d8d1460>, 140004620251504), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(416,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d87b490>, 140004620252384), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(416, 4), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d826490>, 140004620254624), {}).\n",
      "INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(4,), dtype=tf.float64, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f555d853520>, 140004620280016), {}).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Multi_leak/experiment2/withoutswap/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Multi_leak/experiment2/withoutswap/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(model_path)\n",
    "best_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "    0.5438     0.3234     0.1127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_predictions_train = best_model.predict(X_train)\n",
    "# print(\"train\", \"{:10.4f}\".format(mean_squared_error(y_train, y_predictions, squared=True)))\n",
    "y_predictions_val = best_model.predict(X_val)\n",
    "# print(\"val\", \"{:10.4f}\".format(mean_squared_error(y_val, y_predictions, squared=True)))\n",
    "y_predictions = best_model.predict(X_test)\n",
    "\n",
    "loss_test = \"{:10.4f}\".format(mean_squared_error(y_test_sc, y_predictions, squared=True))\n",
    "metric_test = \"{:10.4f}\".format(mean_absolute_error(y_test_sc, y_predictions))\n",
    "\n",
    "loss_val = \"{:10.4f}\".format(mean_squared_error(y_val_sc, y_predictions_val, squared=True))\n",
    "metric_val = \"{:10.4f}\".format(mean_absolute_error(y_val_sc, y_predictions_val))\n",
    "\n",
    "loss_train = \"{:10.4f}\".format(mean_squared_error(y_train_sc, y_predictions_train, squared=True))\n",
    "metric_train = \"{:10.4f}\".format(mean_absolute_error(y_train_sc, y_predictions_train))\n",
    "\n",
    "print(metric_test, metric_val, metric_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.1127\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8111 - mae: 0.5438\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3273 - mae: 0.3234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32734631033016703, 0.32344308668290667]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_train, y_train_sc)\n",
    "best_model.evaluate(X_test, y_test_sc)\n",
    "best_model.evaluate(X_val, y_val_sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studiarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
