{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf # we used tensorflow 2.6.0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "# seeds to make results reproducible\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions for data augmentation\n",
    "\n",
    "def rotate90(df):\n",
    "    df_90 = df.copy()\n",
    "    df_90['mfc1'] = df['mfc4']\n",
    "    df_90['mfc2'] = df['mfc1']\n",
    "    df_90['mfc3'] = df['mfc2']\n",
    "    df_90['mfc4'] = df['mfc3']\n",
    "    for i in [1, 2, 3]:\n",
    "        df_90[f'x{i}'] = 1 - df[f'y{i}']\n",
    "        df_90[f'y{i}'] = df[f'x{i}']\n",
    "    df_90['angle'] = df['angle'] + 90\n",
    "    return df_90\n",
    "\n",
    "def flip(df):\n",
    "    df_flip = df.copy()\n",
    "    df_flip['mfc1'] = df['mfc2']\n",
    "    df_flip['mfc2'] = df['mfc1']\n",
    "    df_flip['mfc3'] = df['mfc4']\n",
    "    df_flip['mfc4'] = df['mfc3']\n",
    "    for i in [1, 2, 3]:\n",
    "        df_flip[f'x{i}'] = 1 - df[f'x{i}']\n",
    "        df_flip[f'y{i}'] = df[f'y{i}']\n",
    "    df_flip['flipped'] = True\n",
    "    return df_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data.csv', index_col=0)\n",
    "\n",
    "# augment data\n",
    "df['angle'] = 0\n",
    "df = df.append(rotate90(df))\n",
    "df = df.append(rotate90(df[(df['angle'] == 90)]))\n",
    "df = df.append(rotate90(df[(df['angle']==180)]))\n",
    "df['flipped'] = False\n",
    "df = df.append(flip(df))\n",
    "\n",
    "# keep only 1-leakage samples (only these are considered in this paper)\n",
    "df = df[df['n'] == 1]\n",
    "\n",
    "# normalize total flow so that x_1 + x_2 + x_3 + x_4 = 1\n",
    "df['mfcsum'] = df['mfc1'] + df['mfc2'] + df['mfc3'] + df['mfc4']\n",
    "df[['mfc1', 'mfc2', 'mfc3', 'mfc4']] = df[['mfc1', 'mfc2', 'mfc3', 'mfc4']].div(df['mfcsum'], axis=0)\n",
    "\n",
    "# remove obsolete columns\n",
    "df.drop(['s1', 'x2', 'y2', 's2', 'x3', 'y3', 's3', 'n', 'mfcsum'], axis=1, inplace=True)\n",
    "\n",
    "# apply coordinate transformation to get (y_1, y_2) in [-1, 1] x [-1, 1]\n",
    "df['x1'] = df['x1'].map(lambda z: 2 * z - 1)\n",
    "df['y1'] = df['y1'].map(lambda z: -2 * z + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and test data\n",
    "X_train = df.loc[(df['split'] == 'train') & (df['angle'] == 0) & (df['flipped'] == False), ['mfc1', 'mfc2', 'mfc3', 'mfc4']].values.astype(np.float32)\n",
    "X_train_augmented = df.loc[(df['split'] == 'train'), ['mfc1', 'mfc2', 'mfc3', 'mfc4']].values.astype(np.float32)\n",
    "X_test = df.loc[(df['split'] == 'test') & (df['angle'] == 0) & (df['flipped'] == False), ['mfc1', 'mfc2', 'mfc3', 'mfc4']].values.astype(np.float32)\n",
    "X_test_augmented = df.loc[(df['split'] == 'test'), ['mfc1', 'mfc2', 'mfc3', 'mfc4']].values.astype(np.float32)\n",
    "Y_train = df.loc[(df['split'] == 'train') & (df['angle'] == 0) & (df['flipped'] == False), ['x1', 'y1']].values.astype(np.float32)\n",
    "Y_train_augmented = df.loc[(df['split'] == 'train'), ['x1', 'y1']].values.astype(np.float32)\n",
    "Y_test = df.loc[(df['split'] == 'test') & (df['angle'] == 0) & (df['flipped'] == False), ['x1', 'y1']].values.astype(np.float32)\n",
    "Y_test_augmented = df.loc[(df['split'] == 'test'), ['x1', 'y1']].values.astype(np.float32)\n",
    "\n",
    "# split validation data from training data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)\n",
    "X_train_augmented, X_val_augmented, Y_train_augmented, Y_val_augmented = train_test_split(X_train_augmented, Y_train_augmented, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom hidden layer for equivariant model\n",
    "class EquivariantHidden(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(EquivariantHidden, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.RandomNormal(stddev=0.2)\n",
    "        self.a = self.add_weight(shape=(), initializer=initializer, trainable=True)\n",
    "        self.b = self.add_weight(shape=(), initializer=initializer, trainable=True)\n",
    "        self.c = self.add_weight(shape=(), initializer=initializer, trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.elu(self.a * inputs + \\\n",
    "                         self.b * (tf.gather(inputs, [3, 2, 1, 0], axis=1) + tf.gather(inputs, [1, 0, 3, 2], axis=1)) + \\\n",
    "                         self.c * tf.gather(inputs, [2, 3, 0, 1], axis=1))\n",
    "    \n",
    "# custom output layer for equivariant model\n",
    "class EquivariantOutput(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(EquivariantOutput, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        initializer = tf.keras.initializers.RandomNormal(stddev=0.2)\n",
    "        self.d = self.add_weight(shape=(), initializer=initializer, trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.d * tf.concat([tf.reduce_sum(inputs * [1, -1, -1, 1], axis=1, keepdims=True),\n",
    "                                   tf.reduce_sum(inputs * [-1, -1, 1, 1], axis=1, keepdims=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and print best hyperparameter configurations from numerical results\n",
    "df_hp = pd.read_csv('results.csv')\n",
    "tmp = df_hp.loc[(df_hp['type']=='eqv') & (df_hp['augmented']==False), 'mse_val']\n",
    "index_eqv = tmp.index[tmp.argmin()]\n",
    "print('\\nEquivariant without data augmentation:\\n')\n",
    "print(df_hp.loc[index_eqv])\n",
    "tmp = df_hp.loc[(df_hp['type']=='eqv') & (df_hp['augmented']==True), 'mse_val']\n",
    "index_eqv_aug = tmp.index[tmp.argmin()]\n",
    "print('\\nEquivariant with data augmentation:\\n')\n",
    "print(df_hp.loc[index_eqv_aug])\n",
    "tmp = df_hp.loc[(df_hp['type']=='fcnn') & (df_hp['augmented']==False), 'mse_val']\n",
    "index_fcnn = tmp.index[tmp.argmin()]\n",
    "print('\\nStandard FCNN without data augmentation:\\n')\n",
    "print(df_hp.loc[index_fcnn])\n",
    "tmp = df_hp.loc[(df_hp['type']=='fcnn') & (df_hp['augmented']==True), 'mse_val']\n",
    "index_fcnn_aug = tmp.index[tmp.argmin()]\n",
    "print('\\nStandard FCNN with data augmentation:\\n')\n",
    "print(df_hp.loc[index_fcnn_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train eqv model without data augmentation\n",
    "hp = df_hp.loc[index_eqv]\n",
    "models = []\n",
    "models_mse = []\n",
    "for i in range(10):\n",
    "    models.append(keras.models.Sequential([EquivariantHidden() for _ in range(hp['depth'])]))\n",
    "    models[-1].add(EquivariantOutput())\n",
    "    models[-1].compile(loss='mse', optimizer=keras.optimizers.Nadam(learning_rate=hp['learning_rate']))\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n",
    "    models[-1].fit(X_train, Y_train, batch_size=hp['batch_size'], epochs=hp['epochs'], validation_data=(X_val, Y_val), callbacks=early_stopping, verbose=0)\n",
    "    models_mse.append(models[-1].evaluate(X_val, Y_val))\n",
    "model_eqv = models[np.argmin(models_mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train eqv model with data augmentation\n",
    "hp = df_hp.loc[index_eqv_aug]\n",
    "models = []\n",
    "models_mse = []\n",
    "for i in range(10):\n",
    "    models.append(keras.models.Sequential([EquivariantHidden() for _ in range(hp['depth'])]))\n",
    "    models[-1].add(EquivariantOutput())\n",
    "    models[-1].compile(loss='mse', optimizer=keras.optimizers.Nadam(learning_rate=hp['learning_rate']))\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n",
    "    models[-1].fit(X_train_augmented, Y_train_augmented, batch_size=hp['batch_size'], epochs=hp['epochs'], validation_data=(X_val, Y_val), callbacks=early_stopping, verbose=0)\n",
    "    models_mse.append(models[-1].evaluate(X_val, Y_val))\n",
    "model_eqv_aug = models[np.argmin(models_mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fcnn model with data augmentation\n",
    "hp = df_hp.loc[index_fcnn]\n",
    "models = []\n",
    "models_mse = []\n",
    "for i in range(10):\n",
    "    models.append(keras.models.Sequential([keras.layers.Dense(hp['width'], activation='elu') for _ in range(hp['depth'])]))\n",
    "    models[-1].add(keras.layers.Dense(2))\n",
    "    models[-1].compile(loss='mse', optimizer=keras.optimizers.Nadam(learning_rate=hp['learning_rate']))\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n",
    "    models[-1].fit(X_train, Y_train, batch_size=hp['batch_size'], epochs=hp['epochs'], validation_data=(X_val, Y_val), callbacks=early_stopping, verbose=0)\n",
    "    models_mse.append(models[-1].evaluate(X_val, Y_val))\n",
    "model_fcnn = models[np.argmin(models_mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fcnn model with data augmentation\n",
    "hp = df_hp.loc[index_fcnn_aug]\n",
    "models = []\n",
    "models_mse = []\n",
    "for i in range(10):\n",
    "    models.append(keras.models.Sequential([keras.layers.Dense(hp['width'], activation='elu') for _ in range(hp['depth'])]))\n",
    "    models[-1].add(keras.layers.Dense(2))\n",
    "    models[-1].compile(loss='mse', optimizer=keras.optimizers.Nadam(learning_rate=hp['learning_rate']))\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n",
    "    models[-1].fit(X_train_augmented, Y_train_augmented, batch_size=hp['batch_size'], epochs=hp['epochs'], validation_data=(X_val, Y_val), callbacks=early_stopping, verbose=0)\n",
    "    models_mse.append(models[-1].evaluate(X_val, Y_val))\n",
    "model_fcnn_aug = models[np.argmin(models_mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model inputs and compute predictions for figure 5\n",
    "const_rates = 0.25 * np.ones(51)\n",
    "increasing_rates = np.arange(0.0, 0.51, 0.01)\n",
    "decreasing_rates = np.arange(0.50, -0.01, -0.01)\n",
    "data_13 = np.c_[increasing_rates, const_rates, decreasing_rates, const_rates]\n",
    "data_24 = np.c_[const_rates, increasing_rates, const_rates, decreasing_rates]\n",
    "predictions_eqv_13 = model_eqv.predict(data_13)\n",
    "predictions_eqv_24 = model_eqv.predict(data_24)\n",
    "predictions_eqv_aug_13 = model_eqv_aug.predict(data_13)\n",
    "predictions_eqv_aug_24 = model_eqv_aug.predict(data_24)\n",
    "predictions_fcnn_13 = model_fcnn.predict(data_13)\n",
    "predictions_fcnn_24 = model_fcnn.predict(data_24)\n",
    "predictions_fcnn_aug_13 = model_fcnn_aug.predict(data_13)\n",
    "predictions_fcnn_aug_24 = model_fcnn_aug.predict(data_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 5a\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_13[:, 0], predictions_eqv_13[:, 1], label='1 $\\leftrightarrow$ 3')\n",
    "plt.scatter(predictions_eqv_24[:, 0], predictions_eqv_24[:, 1], label='2 $\\leftrightarrow$ 4')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_diag_eqv', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 5b\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_aug_13[:, 0], predictions_eqv_aug_13[:, 1], label='1 $\\leftrightarrow$ 3')\n",
    "plt.scatter(predictions_eqv_aug_24[:, 0], predictions_eqv_aug_24[:, 1], label='2 $\\leftrightarrow$ 4')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_diag_eqv_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 5c\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_13[:, 0], predictions_fcnn_13[:, 1], label='1 $\\leftrightarrow$ 3')\n",
    "plt.scatter(predictions_fcnn_24[:, 0], predictions_fcnn_24[:, 1], label='2 $\\leftrightarrow$ 4')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_diag_fcnn', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 5d\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_aug_13[:, 0], predictions_fcnn_aug_13[:, 1], label='1 $\\leftrightarrow$ 3')\n",
    "plt.scatter(predictions_fcnn_aug_24[:, 0], predictions_fcnn_aug_24[:, 1], label='2 $\\leftrightarrow$ 4')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_diag_fcnn_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model inputs and compute predictions for figure 6\n",
    "increasing_rates = np.arange(0.0, 0.51, 0.01)\n",
    "decreasing_rates = np.arange(0.5, -0.01, -0.01)\n",
    "const_rates = 0.25 * np.ones(len(increasing_rates))\n",
    "data_12 = np.c_[increasing_rates, decreasing_rates, const_rates, const_rates]\n",
    "data_34 = np.c_[const_rates, const_rates, increasing_rates, decreasing_rates]\n",
    "data_23 = np.c_[const_rates, increasing_rates, decreasing_rates, const_rates]\n",
    "data_14 = np.c_[increasing_rates, const_rates, const_rates, decreasing_rates]\n",
    "predictions_eqv_34 = model_eqv.predict(data_34)\n",
    "predictions_eqv_12 = model_eqv.predict(data_12)\n",
    "predictions_eqv_23 = model_eqv.predict(data_23)\n",
    "predictions_eqv_14 = model_eqv.predict(data_14)\n",
    "predictions_eqv_aug_34 = model_eqv_aug.predict(data_34)\n",
    "predictions_eqv_aug_12 = model_eqv_aug.predict(data_12)\n",
    "predictions_eqv_aug_23 = model_eqv_aug.predict(data_23)\n",
    "predictions_eqv_aug_14 = model_eqv_aug.predict(data_14)\n",
    "predictions_fcnn_34 = model_fcnn.predict(data_34)\n",
    "predictions_fcnn_12 = model_fcnn.predict(data_12)\n",
    "predictions_fcnn_23 = model_fcnn.predict(data_23)\n",
    "predictions_fcnn_14 = model_fcnn.predict(data_14)\n",
    "predictions_fcnn_aug_34 = model_fcnn_aug.predict(data_34)\n",
    "predictions_fcnn_aug_12 = model_fcnn_aug.predict(data_12)\n",
    "predictions_fcnn_aug_23 = model_fcnn_aug.predict(data_23)\n",
    "predictions_fcnn_aug_14 = model_fcnn_aug.predict(data_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 6a\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_12[:, 0], predictions_eqv_12[:, 1], label='1 $\\leftrightarrow$ 2')\n",
    "plt.scatter(predictions_eqv_34[:, 0], predictions_eqv_34[:, 1], label='3 $\\leftrightarrow$ 4')\n",
    "plt.scatter(predictions_eqv_14[:, 0], predictions_eqv_14[:, 1], label='1 $\\leftrightarrow$ 4', color='lime')\n",
    "plt.scatter(predictions_eqv_23[:, 0], predictions_eqv_23[:, 1], label='2 $\\leftrightarrow$ 3', color='silver')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_adj_eqv', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 6b\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_aug_12[:, 0], predictions_eqv_aug_12[:, 1], label='1 $\\leftrightarrow$ 2')\n",
    "plt.scatter(predictions_eqv_aug_34[:, 0], predictions_eqv_aug_34[:, 1], label='3 $\\leftrightarrow$ 4')\n",
    "plt.scatter(predictions_eqv_aug_14[:, 0], predictions_eqv_aug_14[:, 1], label='1 $\\leftrightarrow$ 4', color='lime')\n",
    "plt.scatter(predictions_eqv_aug_23[:, 0], predictions_eqv_aug_23[:, 1], label='2 $\\leftrightarrow$ 3', color='silver')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_adj_eqv_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 6c\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_12[:, 0], predictions_fcnn_12[:, 1], label='1 $\\leftrightarrow$ 2')\n",
    "plt.scatter(predictions_fcnn_34[:, 0], predictions_fcnn_34[:, 1], label='3 $\\leftrightarrow$ 4')\n",
    "plt.scatter(predictions_fcnn_14[:, 0], predictions_fcnn_14[:, 1], label='1 $\\leftrightarrow$ 4', color='lime')\n",
    "plt.scatter(predictions_fcnn_23[:, 0], predictions_fcnn_23[:, 1], label='2 $\\leftrightarrow$ 3', color='silver')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_adj_fcnn', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce figure 6d\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_aug_12[:, 0], predictions_fcnn_aug_12[:, 1], label='1 $\\leftrightarrow$ 2')\n",
    "plt.scatter(predictions_fcnn_aug_34[:, 0], predictions_fcnn_aug_34[:, 1], label='3 $\\leftrightarrow$ 4')\n",
    "plt.scatter(predictions_fcnn_aug_14[:, 0], predictions_fcnn_aug_14[:, 1], label='1 $\\leftrightarrow$ 4', color='lime')\n",
    "plt.scatter(predictions_fcnn_aug_23[:, 0], predictions_fcnn_aug_23[:, 1], label='2 $\\leftrightarrow$ 3', color='silver')\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, -.9, .9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_adj_fcnn_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.random.uniform(low=0.0, high=1.0, size=(1000000, 4))\n",
    "idx_sum = np.sum(tmp, axis=1) <= 1\n",
    "tmp = tmp[idx_sum, :]\n",
    "idx_1 = (tmp[:, 0] > tmp[:, 1]) & (tmp[:, 0] > tmp[:, 2]) & (tmp[:, 0] > tmp[:, 3])\n",
    "idx_2 = (tmp[:, 1] > tmp[:, 0]) & (tmp[:, 1] > tmp[:, 2]) & (tmp[:, 1] > tmp[:, 3])\n",
    "idx_3 = (tmp[:, 2] > tmp[:, 0]) & (tmp[:, 2] > tmp[:, 1]) & (tmp[:, 2] > tmp[:, 3])\n",
    "idx_4 = (tmp[:, 3] > tmp[:, 0]) & (tmp[:, 3] > tmp[:, 1]) & (tmp[:, 3] > tmp[:, 2])\n",
    "data_1 = tmp[idx_1, :] / np.sum(tmp[idx_1, :], axis=1, keepdims=True)\n",
    "data_2 = tmp[idx_2, :] / np.sum(tmp[idx_2, :], axis=1, keepdims=True)\n",
    "data_3 = tmp[idx_3, :] / np.sum(tmp[idx_3, :], axis=1, keepdims=True)\n",
    "data_4 = tmp[idx_4, :] / np.sum(tmp[idx_4, :], axis=1, keepdims=True)\n",
    "predictions_eqv_1 = model_eqv.predict(data_1)\n",
    "predictions_eqv_2 = model_eqv.predict(data_2)\n",
    "predictions_eqv_3 = model_eqv.predict(data_3)\n",
    "predictions_eqv_4 = model_eqv.predict(data_4)\n",
    "predictions_eqv_aug_1 = model_eqv_aug.predict(data_1)\n",
    "predictions_eqv_aug_2 = model_eqv_aug.predict(data_2)\n",
    "predictions_eqv_aug_3 = model_eqv_aug.predict(data_3)\n",
    "predictions_eqv_aug_4 = model_eqv_aug.predict(data_4)\n",
    "predictions_fcnn_1 = model_fcnn.predict(data_1)\n",
    "predictions_fcnn_2 = model_fcnn.predict(data_2)\n",
    "predictions_fcnn_3 = model_fcnn.predict(data_3)\n",
    "predictions_fcnn_4 = model_fcnn.predict(data_4)\n",
    "predictions_fcnn_aug_1 = model_fcnn_aug.predict(data_1)\n",
    "predictions_fcnn_aug_2 = model_fcnn_aug.predict(data_2)\n",
    "predictions_fcnn_aug_3 = model_fcnn_aug.predict(data_3)\n",
    "predictions_fcnn_aug_4 = model_fcnn_aug.predict(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_1[:, 0], predictions_eqv_1[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_eqv_2[:, 0], predictions_eqv_2[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_eqv_3[:, 0], predictions_eqv_3[:, 1], color='lime', alpha=0.03)\n",
    "plt.scatter(predictions_eqv_4[:, 0], predictions_eqv_4[:, 1], color='silver', alpha=0.03)\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, .9, -.9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_max_eqv', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_eqv_aug_1[:, 0], predictions_eqv_aug_1[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_eqv_aug_2[:, 0], predictions_eqv_aug_2[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_eqv_aug_3[:, 0], predictions_eqv_aug_3[:, 1], color='lime', alpha=0.03)\n",
    "plt.scatter(predictions_eqv_aug_4[:, 0], predictions_eqv_aug_4[:, 1], color='silver', alpha=0.03)\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, .9, -.9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_max_eqv_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_1[:, 0], predictions_fcnn_1[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_2[:, 0], predictions_fcnn_2[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_3[:, 0], predictions_fcnn_3[:, 1], color='lime', alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_4[:, 0], predictions_fcnn_4[:, 1], color='silver', alpha=0.03)\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, .9, -.9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_max_fcnn', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.scatter(predictions_fcnn_aug_1[:, 0], predictions_fcnn_aug_1[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_aug_2[:, 0], predictions_fcnn_aug_2[:, 1], alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_aug_3[:, 0], predictions_fcnn_aug_3[:, 1], color='lime', alpha=0.03)\n",
    "plt.scatter(predictions_fcnn_aug_4[:, 0], predictions_fcnn_aug_4[:, 1], color='silver', alpha=0.03)\n",
    "plt.scatter([-.9, -.9, .9, .9], [-.9, .9, .9, -.9], s=50, facecolor='black', linewidth=0.0)\n",
    "plt.text(-.75, .8, 'MFC1', fontsize=8)\n",
    "plt.text(.42, .8, 'MFC2', fontsize=8)\n",
    "plt.text(.42, -.89, 'MFC3', fontsize=8)\n",
    "plt.text(-.75, -.89, 'MFC4', fontsize=8)\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.grid(True)\n",
    "plt.xticks([0])\n",
    "plt.yticks([0])\n",
    "plt.gca().set_xticklabels([''])\n",
    "plt.gca().set_yticklabels([''])\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig('eusipco_predictions_max_fcnn_aug', pad_inches=0.01, bbox_inches='tight', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
